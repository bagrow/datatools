#!/usr/bin/env python

# aver
# Jim Bagrow
# Last Modified: 2016-09-09

"""
    This file is part of Datatools.
    
    Datatools is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.
    
    Datatools is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.
    
    You should have received a copy of the GNU General Public License
    along with Datatools.  If not, see <http://www.gnu.org/licenses/>.
"""

from __future__ import print_function
import sys, os, math
import numpy
use_scipy = True
try:
    import scipy.stats
except ImportError:
    use_scipy = False
    

name = os.path.basename(sys.argv[0])
usage = \
"""Usage: %s [options] [number of bins]

Average or smooth XY-data received from STDIN by first binning the X-values
then, for each X-bin, compute the mean of all Y-data whose corresponding
X-value is found within that X-bin.

Options:
  -u | --uniq | --unique : Use each unique X-value, instead of binning the X-
                           data. Handy for integer-valued X-data.
  -l | --log             : Use logarithmically increasing bin widths for the X-
                           data. The --unique option overrides this flag.
  -i | --integer         : Use integer bin edges.
  -e | --errorbars       : Return a third column containing the STANDARD 
                           DEVIATION of Y-values in each corresponding X-bin.
  -s | --standard        : Use STANDARD ERROR instead of standard deviation for
                           errorbars.
  -q | --iqr             : Use MEDIAN and INTERQUARTILE RANGE for each X-bin.
                           Overrides any other errorbar settings.
  -p | --prctile         : Compute a particular PERCENTILE for the Y-data in 
                           each X-bin. For example, -p 95 will return the 95th
                           percentile. An integer must be specified following
                           this flag. Don't use with --equal (yet).
     | --rows            : Assumes the data format is not two long columns of
                           XY-data. Instead each row contains a distribution
                           of Y-values for a given X-value, which is the first
                           point. Ie, x y1 y2 ....  Each row's Y-values are
                           used so that aver computes points (x, mean(y)). Rows
                           do not have to be the same length and X-values may
                           be repeated.
     | --sum             : Return sum of all Y-data in each X-bin, instead of the
                           mean. If given, error bars will not be computed.
     | --equal           : Bins are generated by fixing the NUMBER of points in each
                           bin. The mean x and mean y are returned for each bin.
                           Warning: This may lead to multiple "bins" with the
                           same x-coord...
  number of bins         : An integer giving the number of linearly- or 
                           logarithmically-spaced bins to apply to the X-data.
                           Ignored if --unique is used.

Example:
  cat tutorial/xy.dat | %s | plot """ % (name,name)

lmap = lambda func, *iterable: list(map(func, *iterable))

def chunks(l, n):
    """ Yield successive n-sized chunks from l."""
    for i in range(0, len(l), n):
        yield l[i:i+n]


def percentile(N, p):
    """Find the percentile of a list of values.
    
    N - is a list of values. Note N MUST BE already sorted.
    p - a float value from 0.0 to 1.0.
    
    Return the percentile of the values in N.
    
    Adapted from: http://code.activestate.com/recipes/511478/ (r1)
    """
    if not N:
        return float('nan')
    return numpy.percentile(N,p*100.0)

def _iqr(data):
    if not data: return "0.0 0.0"
    data.sort()
    median = percentile(data, 0.50)
    lower  = percentile(data, 0.25)
    upper  = percentile(data, 0.75)
    return "%f %f %f" % (median, lower, upper)

def _mean_stde(data):
    if not data: return "0.0 0.0"
    n = math.sqrt(len(data))
    return "%s %s" % (str(numpy.mean(data)),str(numpy.std(data)/n))

def _mean_stdv(data):
    if not data: return "0.0 0.0"
    return "%s %s" % (str(numpy.mean(data)),str(numpy.std(data)))

def _mean_only(data):
    if not data: return "0.0"
    return "%s" % str(numpy.mean(data))

def _sum_only(data):
    if not data: return "0.0"
    return "%s" % str(sum(data))


def uniq_binning(errorbars=False, standarderror=False, rows=False, sums=False, iqr=False, prctile=False):
    """for each unique x-value, print the mean of all y-values"""
    F = _mean_only
    if sums:
        F = _sum_only
    else:
        if errorbars and not standarderror:
            F = _mean_stdv
        elif errorbars and standarderror:
            F = _mean_stde
        if iqr:
            F = _iqr
        if prctile is not False:
            F = lambda x: percentile(x, prctile/100.0)

    
    x2listy = {}
    if rows:
        for l in sys.stdin:
            if not l.strip():
                continue
            L = l.strip().split()
            x = L[0]
            try:
                x = int(x)    # is x an int?
            except ValueError:
                pass          # nope, keep it a string...
            try:
                x2listy[x].extend( lmap(float,L[1:]) )
            except KeyError:
                x2listy[x] = lmap(float,L[1:])
    else: # data is assumed to be two columns:
        data = [ x.strip().split() for x in sys.stdin if x.strip() ]
        for x,y in data:
            try:
                x = int(x)    # is x an int?
            except ValueError:
                pass          # nope, keep it a string...
            y = float(y)
            try:
                x2listy[x].append(y)
            except KeyError:
                x2listy[x] = [y]
    
    for x in sorted(x2listy.keys()):
        print(x, F(x2listy[x]))


def aver_binning(num_bins, log=False, integer=False, errorbars=False, standarderror=False, iqr=False, rows=False, sums=False, prctile=False):
    """bin the y-values into linear bins by x, print bin center
    and mean of all y values within that bin.
    """
    F = _mean_only # function to apply to the Y-values of each X-bin
    if sums:
        F = _sum_only
    else:
        if errorbars and not standarderror:
            F = _mean_stdv
        elif errorbars and standarderror:
            F = _mean_stde
        if iqr:
            F = _iqr
        if prctile is not False:
            F = lambda x: percentile(x, prctile/100.0)
    
    data =[]
    if rows:
        for l in sys.stdin:
            if not l.strip(): continue
            L = lmap(float, l.strip().split())
            x = L[0]
            for y in L[1:]:
                data.append( (x,y) )
    else: # data is assumed to be two columns:
        data = [ lmap(float, x.strip().split()) for x in sys.stdin if x.strip() ]
    try:
        X,Y = list(zip(*data))
    except ValueError:
        sys.exit("Error: bad data (too many columns?)")
    
    if num_bins is None:
        from math import sqrt
        num_bins = int(sqrt(len(X))) + 1
    
    if log:
        minVal = numpy.log10(min(X))
        maxVal = numpy.log10(max(X)+1e-8)
        if numpy.isinf(minVal):
            sys.exit("Error: For log-binning, the X-data must be non-negative. You have min(X) = %f. Stopping..." % min(X))
        bin_edges = numpy.logspace( minVal, maxVal, num_bins+1 )
    elif integer:
        minVal = int(min(X))
        maxVal = int(max(X)+0.5)
        bin_edges = list(range(minVal, maxVal+1))
    else:
        bin_edges = numpy.linspace( min(X)-1e-8, max(X)+1e-8, num_bins+1 )
    
    if use_scipy: # ugly... :(
        X,Y = numpy.array(X),numpy.array(Y)
        G,H = None,None
        if F == _mean_only:
            F = "mean"
        elif F == _sum_only:
            F = "sum"
        elif F == _mean_stdv:
            F = "mean"
            G = numpy.std
        elif F == _mean_stde:
            F = "mean"
            G = lambda data: numpy.std(data)/math.sqrt(len(data))
        elif F == _iqr:
            F = "median"
            G = lambda data: numpy.percentile(data,25.0)
            H = lambda data: numpy.percentile(data,75.0)
            
        y_bins,bin_edges, misc = scipy.stats.binned_statistic(X,Y, statistic=F, bins=list(bin_edges) )
        x_bins = (bin_edges[:-1]+bin_edges[1:])/2
        if H:
            y_25,bin_edges, misc = scipy.stats.binned_statistic(X,Y, statistic=G, bins=list(bin_edges) )
            y_75,bin_edges, misc = scipy.stats.binned_statistic(X,Y, statistic=H, bins=list(bin_edges) )
            for x,y,el,er in zip(x_bins,y_bins,y_25,y_75):
                print(x,y, el,er)
        elif G:
            y_e,bin_edges, misc = scipy.stats.binned_statistic(X,Y, statistic=G, bins=list(bin_edges) )
            for x,y,e in zip(x_bins,y_bins,y_e):
                print(x,y, e)
        else:
            for x,y in zip(x_bins,y_bins):
                print(x, y)
    
    else: # Fall back to slow way...
        bL,bR, data_in_bin, b = bin_edges[0],bin_edges[1], [], 0
        data.sort()
        while data:
            x,y = data.pop(0)
            in_bin = False
            while not in_bin:
                if bL <= x < bR:
                    data_in_bin.append( y )
                    in_bin = True
                elif x >= bR:
                    print(0.5*(bL+bR), F( data_in_bin )) # print current bin
                    b += 1                              # go to next bin, but with same x,y
                    bL, bR = bin_edges[b], bin_edges[b+1] # careful about IndexError...
                    data_in_bin = []
        print(0.5*(bL+bR), F( data_in_bin )) # don't forget last bin!


def equal_binning(num_bins, errorbars=False, standarderror=False, iqr=False, rows=False, sums=False, prctile=False):
    """Bins are defined by dividing the number of xy-points into evenly sized
    groups, then return the average x and average y for each group.
    """
    F = _mean_only # function to apply to the Y-values of each X-bin
    if sums:
        F = _sum_only
    else:
        if errorbars and not standarderror:
            F = _mean_stdv
        elif errorbars and standarderror:
            F = _mean_stde
        if iqr:
            F = _iqr
        if prctile is not False:
            F = lambda x: percentile(x, prctile/100.0)
    
    data =[]
    if rows:
        for l in sys.stdin:
            if not l.strip(): continue
            L = lmap(float, l.strip().split())
            x = L[0]
            for y in L[1:]:
                data.append( (x,y) )
    else: # data is assumed to be two columns:
        data = [ lmap(float, x.strip().split()) for x in sys.stdin if x.strip() ]
    try:
        X,Y = list(zip(*data))
    except ValueError:
        sys.exit("Error: bad data (too many columns?)")
    
    data.sort() # !!!
    
    if num_bins is None:
        num_bins = 10 # ??? keep
    
    num_points = len(data)
    points_per_bin = int(1.0*num_points / num_bins)
    D = list(chunks(data, points_per_bin))
    if len(D[-1]) < len(D[-2]):
        D[-2] += D[-1]
        D.pop()
    
    for chunk in D:
        xd,yd = list(zip(*chunk))
        print(F(list(xd)),F(list(yd)))


if __name__ == '__main__':
    if '-h' in sys.argv or '--help' in sys.argv:
        sys.exit( usage )
    
    # parse commandline arg:
    largs = [a.lower() for a in sys.argv[1:]] # only for prctile flag...
    args = set( largs )
    
    errorbars = False
    stanerror = False
    iqr       = False
    rows      = False
    sums      = False
    if set(['-e','--error','--errorbars']) & args:
        errorbars = True
    if set(['-s','--standard','--standarderror']) & args:
        errorbars = True
        stanerror = True
    if set(['-q','--iqr']) & args:
        iqr = True
    if set(['-r','--rows']) & args:
        rows = True
    if "--sum" in args:
        sums = True
    
    # check if user wants to compute a particular percentile for each bin:
    prctile = False
    if largs and not errorbars and not stanerror and not iqr and not sums:
        for i,a in enumerate(largs):
            if a in set(['-p','--prctile','--percentile']):
                try:
                    prctile = int(largs[i+1])
                except IndexError:
                    sys.exit("Error: percentile not specified")
                except ValueError:
                    sys.exit("Error: percentile must be integer")
    
    
    if set(['-u','--uniq','--unique']) & args:
        uniq_binning(errorbars=errorbars, rows=rows, sums=sums, standarderror=stanerror, iqr=iqr, prctile=prctile)
    elif set(['--equal']) & args:
        try:
            if len(largs) > 1:
                num_bins = int(sys.argv[-1]) if sys.argv[-2] not in set(['-p','--prctile','--percentile']) else None
            else:
                num_bins = int(sys.argv[-1])
        except ValueError:
            num_bins = None
        equal_binning(num_bins, errorbars=errorbars, rows=rows, sums=sums, standarderror=stanerror, iqr=iqr, prctile=prctile)
    else:
        log,integer = False,False
        if set(['-l','--log']) & args:
            log = True
        if set(['-i','--int','--ints','--integer','--integers']) & args:
            integer = True
        if log and integer:
            sys.exit("Error: cannot specific log and integer bins")
        try:
            if len(largs) > 1:
                num_bins = int(sys.argv[-1]) if sys.argv[-2] not in set(['-p','--prctile','--percentile']) else None
            else:
                num_bins = int(sys.argv[-1])
        except ValueError:
            num_bins = None
        aver_binning(num_bins, log=log, integer=integer, errorbars=errorbars, rows=rows, sums=sums, standarderror=stanerror, iqr=iqr, prctile=prctile)
    
